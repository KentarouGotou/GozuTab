{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, data_dir_path=\"preprocessed/\", mode=\"cqt\", context_window=9):\n",
    "        self.data_dir_path = data_dir_path\n",
    "        self.mode = mode\n",
    "        self.context_window = context_window\n",
    "        self.half_context_window = int(self.context_window / 2)\n",
    "        self.tab_data_paths = self.get_tab_data_paths()\n",
    "        self.audio_data_paths = self.get_audio_data_paths()\n",
    "        \n",
    "        if self.mode == \"cqt\":\n",
    "            self.full_audio_length = 2000\n",
    "        elif self.mode == \"melspec\":\n",
    "            self.full_audio_length = 2000\n",
    "        \n",
    "    def get_tab_data_paths(self):\n",
    "        data_paths = []\n",
    "        tab_dir_path = os.path.join(self.data_dir_path, \"tab\")\n",
    "        for file in os.listdir(tab_dir_path):\n",
    "            data_paths.append(os.path.join(tab_dir_path, file))\n",
    "        return data_paths\n",
    "    \n",
    "    def get_audio_data_paths(self):\n",
    "        data_paths = []\n",
    "        audio_dir_path = os.path.join(self.data_dir_path, self.mode)\n",
    "        for file in os.listdir(audio_dir_path):\n",
    "            data_paths.append(os.path.join(audio_dir_path, file))\n",
    "        return data_paths\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tab_data_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # data path\n",
    "        tab_data_path = self.tab_data_paths[index]\n",
    "        audio_data_path = self.audio_data_paths[index]\n",
    "        # load data\n",
    "        loaded_tab_data = np.load(tab_data_path)\n",
    "        tempo = loaded_tab_data[\"tempo\"]\n",
    "        tab_data = loaded_tab_data[\"tab\"]\n",
    "        loaded_audio_data = np.load(audio_data_path)\n",
    "        \n",
    "        # generate audio data\n",
    "        audio_data = np.empty((self.full_audio_length, loaded_audio_data.shape[0], self.context_window))\n",
    "        # padding\n",
    "        full_audio_data = np.pad(loaded_audio_data, ((0, 0), (0, self.full_audio_length - loaded_audio_data.shape[1])))\n",
    "        padd_audio_data = np.pad(full_audio_data, ((0, 0), (self.half_context_window, self.half_context_window)))\n",
    "        # insert\n",
    "        for i in range(self.full_audio_length):\n",
    "            audio_data[i] = padd_audio_data[:, i:i+self.context_window]\n",
    "        # expand dim\n",
    "        audio_data = np.expand_dims(audio_data, -1)\n",
    "        return tempo, tab_data, audio_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 192, 9, 1)\n",
      "(75, 21)\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset()\n",
    "tempo, tab_data, audio_data = dataset[0]\n",
    "print(audio_data.shape)\n",
    "print(tab_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 21)\n",
      "[120] [[5. 0. 0. ... 2. 0. 1.]\n",
      " [0. 6. 0. ... 2. 0. 1.]\n",
      " [0. 0. 7. ... 2. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 2. 0. 1.]\n",
      " [0. 0. 0. ... 1. 0. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "data = np.load(\"preprocessed/tab/test2.npz\")\n",
    "tempo = data[\"tempo\"]\n",
    "tab = data[\"tab\"]\n",
    "print(tab.shape)\n",
    "print(tempo, tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192, 1322)\n",
      "[[1.03439415e-04 1.02625061e-04 9.77542149e-05 ... 6.76293275e-04\n",
      "  6.87648659e-04 6.91265857e-04]\n",
      " [1.73491731e-04 1.71410124e-04 1.71554449e-04 ... 7.12694658e-04\n",
      "  7.04140344e-04 6.99724362e-04]\n",
      " [3.00559797e-04 3.00102198e-04 2.90700031e-04 ... 3.17597995e-04\n",
      "  3.36186873e-04 3.50715418e-04]\n",
      " ...\n",
      " [1.72285014e-04 3.68449801e-05 1.67578954e-04 ... 1.41001670e-04\n",
      "  1.17982323e-04 7.07401196e-05]\n",
      " [8.88005015e-05 5.41087138e-05 4.49347899e-05 ... 5.49771648e-05\n",
      "  1.49864354e-04 8.48159543e-05]\n",
      " [5.98453662e-05 1.45750309e-04 1.00274119e-04 ... 9.79508332e-05\n",
      "  1.27555453e-04 8.62547167e-05]]\n"
     ]
    }
   ],
   "source": [
    "audio_data = np.load(\"preprocessed/cqt/test2.npy\")\n",
    "print(audio_data.shape)\n",
    "print(audio_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
