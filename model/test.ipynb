{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, data_dir_path=\"preprocessed/\", mode=\"cqt\", plot=False):\n",
    "        self.data_dir_path = data_dir_path\n",
    "        self.mode = mode\n",
    "        self.plot = plot\n",
    "        \n",
    "        # data paths\n",
    "        self.tab_data_paths = self.get_tab_data_paths()\n",
    "        self.audio_data_paths = self.get_audio_data_paths()\n",
    "        \n",
    "        # audio max length\n",
    "        if self.mode == \"raw_wave\":\n",
    "            self.full_audio_length = 5000000\n",
    "        else:\n",
    "            self.full_audio_length = 8192\n",
    "        # tab max length\n",
    "        self.full_tab_length = 512\n",
    "        # padding tab\n",
    "        self.padding_tab = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0]\n",
    "        \n",
    "    def get_tab_data_paths(self):\n",
    "        data_paths = []\n",
    "        tab_dir_path = os.path.join(self.data_dir_path, \"tab\")\n",
    "        for file in os.listdir(tab_dir_path):\n",
    "            data_paths.append(os.path.join(tab_dir_path, file))\n",
    "        return data_paths\n",
    "    \n",
    "    def get_audio_data_paths(self):\n",
    "        data_paths = []\n",
    "        audio_dir_path = os.path.join(self.data_dir_path, self.mode)\n",
    "        for file in os.listdir(audio_dir_path):\n",
    "            data_paths.append(os.path.join(audio_dir_path, file))\n",
    "        return data_paths\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tab_data_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # data path\n",
    "        tab_data_path = self.tab_data_paths[index]\n",
    "        audio_data_path = self.audio_data_paths[index]\n",
    "        # load data\n",
    "        loaded_tab_data = np.load(tab_data_path)\n",
    "        tempo = loaded_tab_data[\"tempo\"]\n",
    "        tab_data = loaded_tab_data[\"tab\"]\n",
    "        loaded_audio_data = np.load(audio_data_path)\n",
    "        \n",
    "        # generate audio data\n",
    "        if self.mode == \"raw_wave\":\n",
    "            audio_data = np.pad(loaded_audio_data, [(0, self.full_audio_length - loaded_audio_data.shape[0])])\n",
    "            # expand dimension\n",
    "            audio_data = np.expand_dims(audio_data, axis=1)\n",
    "            # transpose\n",
    "            audio_data = np.transpose(audio_data, (1, 0))\n",
    "        else:\n",
    "            audio_data = np.pad(loaded_audio_data, [(0, 0), (0, self.full_audio_length - loaded_audio_data.shape[1])])\n",
    "            # expand dimension\n",
    "            audio_data = np.expand_dims(audio_data, axis=2)\n",
    "            # transpose\n",
    "            audio_data = np.transpose(audio_data, (2, 0, 1))\n",
    "        \n",
    "        # generate tab data\n",
    "        # padding\n",
    "        padding_tab_data = [self.padding_tab for i in range(self.full_tab_length - tab_data.shape[0])]\n",
    "        tab_data = np.concatenate([tab_data, padding_tab_data])\n",
    "        \n",
    "        # plot\n",
    "        if self.plot:\n",
    "            print(\"Tab data shape: \", tab_data.shape, \"Audio data shape: \", audio_data.shape)\n",
    "            # Tab data\n",
    "            print(\"Tab data: \", tab_data[0])\n",
    "            # Audio data\n",
    "            plt.figure(figsize=(16, 9))\n",
    "            plt.imshow(audio_data[1000:1200], cmap=\"jet\")\n",
    "            plt.show()\n",
    "        return tempo, tab_data, audio_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 192, 8192)\n",
      "(512, 21)\n",
      "(1, 5000000)\n"
     ]
    }
   ],
   "source": [
    "import getdataset as gd\n",
    "\n",
    "cqt_dataset = Dataset()\n",
    "melspec_dataset = Dataset(mode='melspec')\n",
    "raw_wave_dataset = Dataset(mode='raw_wave')\n",
    "stft_dataset = Dataset(mode='stft')\n",
    "tempo, tab_data, audio_data = cqt_dataset[1]\n",
    "print(audio_data.shape)\n",
    "print(tab_data.shape)\n",
    "tempo, tab_data, audio_data = melspec_dataset[3]\n",
    "\n",
    "tempo, tab_data, audio_data = raw_wave_dataset[7]\n",
    "print(audio_data.shape)\n",
    "tempo, tab_data, audio_data = stft_dataset[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8192\n"
     ]
    }
   ],
   "source": [
    "print(2**13)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
